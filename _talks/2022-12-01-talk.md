---
title: "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables"
collection: talks
type: "Lab Seminar"
permalink: /talks/2022-12-01-talk
venue: "NYCU-ED824"
date: 2022-12-01
location: "Hsinchu city, Taiwan"
---

Previous methods rely heavily on on-policy experience, limiting their sample efficiency.
 
They also lack mechanisms to reason about task uncertainty when adapting to new tasks, limiting their effectiveness in sparse reward problems.
 
This paper developing an off-policy meta-RL algorithm that disentangles task inference and control.
1. Achieving excellent sample efficiency during meta-training, enables fast adaptation by accumulating experience online
2. Performing structured exploration by reasoning about uncertainty over tasks

**Video from the author**
 
[GTC 2020: Efficient Meta-Reinforcement Learning via Probabilistic Context Variables](https://developer.nvidia.com/gtc/2020/video/s21869-vid)

**Reference paper**
1. [Soft Actor-Critic](https://arxiv.org/abs/1801.01290)
2. [$\rm{RL}^{2}$](https://arxiv.org/abs/1611.02779)
3. [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://arxiv.org/abs/1703.03400)
4. [MAESN](https://arxiv.org/abs/1802.07245)
 
Powerpoint for this talk
======
[Powerpoint for this talk](https://drive.google.com/file/d/1aYNxeoAxnVt5RWHDtZzxMNUauM3NDFd4/view?usp=share_link)
