---
title: "Active Retrieval Augmented Generation"
collection: talks
type: "RL Group Meeting"
permalink: /talks/2023-06-27-talk
venue: "Hsinchu city, National Yang Ming Chiao Tung University"
date: 2023-06-27
location: "Hsinchu city, Taiwan"
---

Most existing retrieval-augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. 

This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout the generation process is essential.

This paper propose **F**orward-**L**ooking **A**ctive **RE**trieval augmented generation (FLARE), a generic retrieval-augmented generation method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to **retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens**.

Powerpoint for this talk
=====
<iframe src="https://www.slideshare.net/slideshow/embed_code/key/bsrEzesLgrVtoA?startSlide=1" width="100%" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe>

Reference Paper
=====
- [Measuring and Narrowing the Compositionality Gap in Language Models](https://arxiv.org/abs/2210.03350)
- [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/abs/2302.04761)
- [Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions](https://arxiv.org/abs/2212.10509)
- [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)
- [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf)
