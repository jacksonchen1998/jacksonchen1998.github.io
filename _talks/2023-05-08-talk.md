---
title: "Off-Policy Deep Reinforcement Learning without Exploration"
collection: talks
type: "Course paper presentation"
permalink: /talks/2023-05-08-talk
venue: "Hsinchu city, National Yang Ming Chiao Tung University"
date: 2023-05-08
location: "Hsinchu city, Taiwan"
---

This paper proposes a new algorithm for off-policy reinforcement learning that combines state-of-the-art deep Q-learning algorithms with a state-conditioned generative model for producing only previously seen actions.

Their algorithm, Batch-Constrained deep Q-learning (BCQ), uses the generative model to propose candidate actions with high similarity to the batch, and then selects the highest valued action through a learned Q-network.

OpenReview for this presentation
===
[NYCU RL Theory Challenge 2023](https://openreview.net/group?id=NYCU/2023/RL_Theory_Challenge&referrer=%5BHomepage%5D(%2F))

Powerpoint for this talk
=====
[Powerpoint for this talk](https://www.slideshare.net/jacksonChen22/offpolicy-deep-reinforcement-learning-without-explorationpdf)

Reference Paper
=====
- [Reinforcement learning: An introduction.](https://mitpress.mit.edu/9780262039246/reinforcement-learning/)
- [Deep reinforcement learning with double q-learning](https://arxiv.org/abs/1509.06461)
- [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/abs/1511.06581)
- [Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor](https://arxiv.org/abs/1801.01290)
- [Trust region policy optimization](https://arxiv.org/abs/1502.05477)
- [Learning From Delayed Rewards](https://www.researchgate.net/publication/33784417_Learning_From_Delayed_Rewards)
- [Deep Reinforcement Learning with Double Q-learning](https://arxiv.org/abs/1509.06461)
